{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark=SparkSession.builder.appName('myApp').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import (IntegerType,StringType,StructField,StructType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylist = [[1, 2, 3, 4,5],[4,5,6,8,9],[7,8,5,4,4],[3,6,4,8,6],[5,7,6,2,1]]\n",
    "#mylist = [5,7,6,2,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark.createDataFrame(mylist,IntegerType()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cSchema = StructType([StructField(\"a\", IntegerType()),StructField(\"b\", IntegerType()),StructField(\"c\", IntegerType()),StructField(\"d\", IntegerType()),StructField(\"e\", IntegerType())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark.createDataFrame(mylist,IntegerType()).show()\n",
    "df = spark.createDataFrame(mylist,schema=cSchema) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+---+\n",
      "|  a|  b|  c|  d|  e|\n",
      "+---+---+---+---+---+\n",
      "|  1|  2|  3|  4|  5|\n",
      "|  4|  5|  6|  8|  9|\n",
      "|  7|  8|  5|  4|  4|\n",
      "|  3|  6|  4|  8|  6|\n",
      "|  5|  7|  6|  2|  1|\n",
      "+---+---+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.window import Window as W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+---+-----+\n",
      "|  a|  b|  c|  d|  e|TOTAL|\n",
      "+---+---+---+---+---+-----+\n",
      "|  1|  2|  3|  4|  5|   15|\n",
      "|  4|  5|  6|  8|  9|   32|\n",
      "|  7|  8|  5|  4|  4|   28|\n",
      "|  3|  6|  4|  8|  6|   27|\n",
      "|  5|  7|  6|  2|  1|   21|\n",
      "+---+---+---+---+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn('TOTAL', df.a + df.b + df.c + df.d+ df.e).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "newDf =df.withColumn('TOTAL', df.a + df.b + df.c + df.d+ df.e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+---+-----+----------+\n",
      "|  a|  b|  c|  d|  e|TOTAL|prev_value|\n",
      "+---+---+---+---+---+-----+----------+\n",
      "|  1|  2|  3|  4|  5|   15|      null|\n",
      "|  3|  6|  4|  8|  6|   27|        15|\n",
      "|  4|  5|  6|  8|  9|   32|        27|\n",
      "|  5|  7|  6|  2|  1|   21|        32|\n",
      "|  7|  8|  5|  4|  4|   28|        21|\n",
      "+---+---+---+---+---+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_window = Window.partitionBy().orderBy(\"a\")\n",
    "\n",
    "df1 = newDf.withColumn(\"prev_value\", F.lag(newDf.TOTAL).over(my_window))\n",
    "\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.withColumn(\"diff\", F.when(F.isnull(df1.TOTAL - df1.prev_value), 0)\n",
    "                             .when((df1.TOTAL==32), 0)\n",
    "                              .otherwise(df1.TOTAL + df1.prev_value))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+---+-----+----------+----+\n",
      "|  a|  b|  c|  d|  e|TOTAL|prev_value|diff|\n",
      "+---+---+---+---+---+-----+----------+----+\n",
      "|  1|  2|  3|  4|  5|   15|      null|   0|\n",
      "|  3|  6|  4|  8|  6|   27|        15|  42|\n",
      "|  4|  5|  6|  8|  9|   32|        27|   0|\n",
      "|  5|  7|  6|  2|  1|   21|        32|  53|\n",
      "|  7|  8|  5|  4|  4|   28|        21|  49|\n",
      "+---+---+---+---+---+-----+----------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
